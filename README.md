# üè† MLOps Pipeline for California Housing Price Prediction

This project demonstrates a full end-to-end MLOps workflow using the California Housing dataset with the following technologies:

- ‚úÖ **Git + DVC** for data & model versioning
- üìä **MLflow** for experiment tracking
- ‚öôÔ∏è **FastAPI** for model serving
- üê≥ **Docker** for containerization
- üîÅ **GitHub Actions** for CI/CD
- ÔøΩ **Pydantic** for data validation
- üìä **Prometheus & Grafana** for monitoring and visualization
- ÔøΩüîç **Logging & Metrics** with detailed monitoring

---

## üìÅ Folder Structure

```
mlops-housing/
‚îú‚îÄ‚îÄ data/                # Contains housing.csv (tracked via DVC)
‚îú‚îÄ‚îÄ models/              # Stores best_model.pkl (generated by training)
‚îú‚îÄ‚îÄ logs/                # API logs
‚îú‚îÄ‚îÄ src/                 # Python source code
‚îÇ   ‚îú‚îÄ‚îÄ train.py         # Model training and MLflow logging
‚îÇ   ‚îú‚îÄ‚îÄ app.py           # FastAPI inference app
‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py  # Data preparation with validation
‚îÇ   ‚îú‚îÄ‚îÄ validate.py      # Model validation
‚îÇ   ‚îî‚îÄ‚îÄ schema.py        # Pydantic schemas for data validation
‚îú‚îÄ‚îÄ grafana/             # Grafana dashboards and configuration
‚îÇ   ‚îú‚îÄ‚îÄ dashboards/      # Dashboard JSON definitions
‚îÇ   ‚îî‚îÄ‚îÄ provisioning/    # Auto-provisioning configuration
‚îú‚îÄ‚îÄ params.yaml          # Model hyperparameters
‚îú‚îÄ‚îÄ dvc.yaml             # DVC pipeline
‚îú‚îÄ‚îÄ Dockerfile           # Docker container definition
‚îú‚îÄ‚îÄ docker-compose.yml   # Multi-container Docker composition
‚îú‚îÄ‚îÄ prometheus.yml       # Prometheus configuration
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îú‚îÄ‚îÄ ARCHITECTURE.md      # Architecture documentation
‚îú‚îÄ‚îÄ .github/workflows/ci-cd.yml  # GitHub Actions CI/CD
```

---

## üõ†Ô∏è Prerequisites

- Python ‚â• 3.10
- Git
- DVC (`pip install dvc`)
- Docker
- GitHub account + Docker Hub account

---

## üöÄ Step-by-Step Execution

### 1Ô∏è‚É£ Clone the Project or Unzip

```bash
unzip mlops-housing.zip
cd mlops-housing
```

### 2Ô∏è‚É£ Create a Virtual Environment and Install Dependencies

```bash
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3Ô∏è‚É£ Generate and Save the Dataset (Run Once)

```python
# save_dataset.py
from sklearn.datasets import fetch_california_housing
import pandas as pd
df = fetch_california_housing(as_frame=True).frame
df.rename(columns={'MedHouseVal': 'Price'}, inplace=True)
df.to_csv("data/housing.csv", index=False)
```

Then run:

```bash
python save_dataset.py
```

### 4Ô∏è‚É£ Initialize DVC and Track the Dataset

```bash
dvc init
dvc add data/housing.csv
echo "data/housing.csv" >> .gitignore
git add data/housing.csv.dvc .gitignore
git commit -m "Track dataset with DVC"
```

### 5Ô∏è‚É£ Reproduce the Pipeline with DVC

```bash
dvc repro
```

‚úÖ This runs training and saves `models/best_model.pkl`.

---

## üìä View Experiments in MLflow

```bash
mlflow ui
```

Then open [http://localhost:5000](http://localhost:5000) in your browser.

---

## üåê Serve the Model with FastAPI

```bash
uvicorn src.app:app --reload
```

Visit: [http://localhost:8000/docs](http://localhost:8000/docs) to test `/predict`.

Example payload:

```json
{
  "MedInc": 8.3,
  "HouseAge": 20,
  "AveRooms": 6,
  "AveBedrms": 1,
  "Population": 500,
  "AveOccup": 2.5,
  "Latitude": 37,
  "Longitude": -122
}
```

‚úÖ You‚Äôll get a prediction like:

```json
{"prediction": 2.85}
```

---

## üìà Monitoring with Prometheus and Grafana

### View Raw Metrics

Visit: [http://localhost:8000/metrics](http://localhost:8000/metrics)

Output includes:
```
# HELP housing_predictions_total Number of predictions made
# TYPE housing_predictions_total counter
housing_predictions_total 5

# HELP prediction_duration_seconds Time spent processing prediction
# TYPE prediction_duration_seconds histogram
prediction_duration_seconds_bucket{le="0.005"} 3
...

# HELP model_version Model version
# TYPE model_version gauge
model_version 1.0
```

### View Dashboards

1. **Prometheus UI**: [http://localhost:9090](http://localhost:9090)
   - Explore and query raw metrics
   - Check target status
   - Execute PromQL queries

2. **Grafana Dashboard**: [http://localhost:3000](http://localhost:3000)
   - Login with admin/admin
   - Access the pre-configured "Housing Predictions Dashboard"
   - View metrics like:
     - Total predictions
     - Prediction latency (95th percentile)
     - Model version

---

## üê≥ Build and Run with Docker Compose

```bash
docker-compose up --build
```

This will start:
1. The FastAPI application on port 8000
2. Prometheus server on port 9090
3. Grafana on port 3000 (login: admin/admin)

---

## üîÅ Set Up GitHub Actions CI/CD

1. Push project to a GitHub repository:

```bash
git remote add origin https://github.com/YOUR_USERNAME/mlops-housing.git
git branch -M main
git push -u origin main
```

2. Add GitHub Secrets:
   - `DOCKER_USERNAME`
   - `DOCKER_PASSWORD`

3. On push, GitHub Actions will:
   - Run training
   - Build Docker image
   - Push to Docker Hub

---

## üîÅ Re-run with Different Hyperparameters

Edit `params.yaml`:

```yaml
model:
  max_depth: 10
```

Then rerun:

```bash
dvc repro
```

---

## ‚úÖ Summary

| Task                     | Tool Used             |
|--------------------------|----------------------|
| Data versioning          | DVC                  |
| Code versioning          | Git                  |
| Training                 | Scikit-learn         |
| Experiment tracking      | MLflow               |
| Data validation          | Pydantic             |
| Serving                  | FastAPI              |
| Deployment               | Docker               |
| Orchestration            | Docker Compose       |
| Monitoring               | Prometheus           |
| Visualization            | Grafana              |
| Automation               | GitHub Actions       |

---

## üèõÔ∏è Architecture

For a detailed architectural overview, see [ARCHITECTURE.md](./ARCHITECTURE.md).

## üì¨ Questions?

Feel free to reach out or raise an issue if you'd like help deploying this to cloud platforms like EC2 or extending the monitoring capabilities.
